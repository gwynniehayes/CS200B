---
title: "modeling"
format: html
editor_options: 
  chunk_output_type: console
---
```{r}
library(reticulate)
py_install("pandas")
py_install("pip")
py_install("plotnine")
py_install("seaborn")
py_install("scikit-learn")
py_require("XGBoost")
```

```{python}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

seed = 42
np.random.seed(seed)

yarn = pd.read_csv("~/Desktop/16/CS200B/final_yarn.csv")
```

```{python}
y = yarn['fiber_type_id']

drop_cols = ['fiber_type_name', 'name', 'permalink',
             'yarn_company_name', 'fiber_type_id']
X = yarn.drop(columns=drop_cols)

categorical_cols = X.select_dtypes(include='object').columns
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)
```

```{python}
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', 'passthrough'),
    ('classifier', 'passthrough')])

dt  = DecisionTreeClassifier(random_state=seed)
knn = KNeighborsClassifier()
log_reg = LogisticRegression(max_iter=9000, solver='saga', random_state=seed)
rf  = RandomForestClassifier(random_state=seed)
```

```{python}
param_grid = [
    # Decision Tree
    {
        'classifier': [dt],
        'classifier__max_depth': [None, 5, 10],
        'classifier__min_samples_split': [2, 5],
        'classifier__min_samples_leaf': [1, 2]},

    # KNN
    {
        'pca': ['passthrough', PCA(n_components=0.95)],
        'classifier': [knn],
        'classifier__n_neighbors': [5, 7, 9],
        'classifier__weights': ['uniform', 'distance']},

    # Logistic Regression
    {
        'pca': ['passthrough', PCA(n_components=0.95)],
        'classifier': [log_reg],
        'classifier__C': [0.01, 0.1, 1, 5, 10]},

    # Random Forest
    {
        'classifier': [rf],
        'classifier__n_estimators': [100, 200],
        'classifier__max_depth': [None, 5, 10]}]
```

```{python}
grid_search = GridSearchCV(
    pipe,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=2)

grid_search.fit(X_train, y_train)
```

```{python}
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

print("Best parameters:\n", grid_search.best_params_)
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n",
      classification_report(y_test, y_pred))
```

```{python}
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
```

